{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch02 - Perceptron and Adaline algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../assets/workout.png\"\n",
    "     alt=\"Hierarchical clustering\"\n",
    "     style=\"width: 100px; float: right; margin: 20px\" />\n",
    "\n",
    "__Welcome to the practice exercises for chapter 02!__\n",
    "\n",
    "The exercises are divided into two parts: A theoretical (quiz) part, and a practical part where you get to know the code behind the Perceptron and Adaline classes and try them in practice comparing results.\n",
    "\n",
    "It is highly recommended to complete the quiz and understand the underlying theory __first__, before completing the more practical exercises.\n",
    "\n",
    "__Enjoy!__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "<img src=\"../../assets/quiz.jpg\"\n",
    "     alt=\"quiz\"\n",
    "     style=\"width: 100px; float: right\" />\n",
    "\n",
    "## Part I: Quiz-time <a class=\"anchor\" id=\"quiz\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1:__\n",
    "\n",
    "Considering the following formulas:\n",
    "$$w_{j} := w_{j} + \\Delta w_{j}$$\n",
    "$$where$$\n",
    "$$\\Delta w_{j} = \\eta (y^{i} - \\hat{y}^{j}) x_{j}^{(i)}$$\n",
    "\n",
    "Explain the meaning of different symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$w_{j}$ : A single weight in the perceptron, and part of the weight vector, _w_.\n",
    "\n",
    "$\\Delta w_{j}$ : The update to the weight as a result of the perceptron learning rule. (A function of the learning rate and prediction error)\n",
    "\n",
    "$y^{i}$ : The true target, in this case -1 or 1.\n",
    "\n",
    "$\\hat{y}^{i}$ : The predicted target, in this case -1 or 1. \n",
    "\n",
    "$\\eta$ : The learning rate (typically between 0 and 1) which decides the magnitude of updates to individual weights after each prediction.\n",
    "\n",
    "$x_{j}^{(i)}$ : The input value of the the training sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2:__\n",
    "\n",
    "Calculate the $\\Delta w_{j}$ for the following examples:\n",
    "\n",
    "|task|$y^{j}$|$\\hat{y}^{j}$|learning rate|$x_{j}^{(i)}$|$\\Delta w_{j}$|\n",
    "|---|---|---|---|---|---|\n",
    "|A|1|1|0.1|0.5|??|\n",
    "|B|-1|1|1|0.9|??|\n",
    "|C|1|-1|2|1.2|??|\n",
    "|D|-1|-1|0.05|0.05|??|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "A: 0\n",
    "\n",
    "B: 1.8\n",
    "\n",
    "C: 4.8\n",
    "\n",
    "D: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3:__\n",
    "\n",
    "Consider the following image:\n",
    "\n",
    "<img src=\"../images/perceptronadaline.png\"\n",
    "     alt=\"Perceptron and Adaline\"\n",
    "     style=\"width: 500px\" />\n",
    "\n",
    "Explain with your own words the key difference between the Perceptron and Adaline classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The Perceptron rule is defined by a step-wise activation function either _fires or it doesn't_. The Adaline activation is linear, meaning weights can be updated according to _how wrong_ or _how confident_ the model is. This makes for large updates in weights where the model is drastically wrong, and small nudges in the right direction where it is only slightly wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<img src=\"../../assets/practice.png\"\n",
    "     alt=\"practice\"\n",
    "     style=\"width: 100px; float: right\" />\n",
    "\n",
    "## Part II:Complete the Percetron classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try to implement as much as possible without consulting the solution.**\n",
    "\n",
    "*Purpose: Acquire a lasting understanding of basic and complex ML-algorithms by implementing weights, gradient descent and more by hand.*\n",
    "\n",
    "**Resources:**\n",
    "* Solution: Ch02 - page 27, 3rd Edition or in lecture notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T08:54:55.417301Z",
     "start_time": "2021-01-07T08:54:55.393536Z"
    }
   },
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    errors_ : list\n",
    "      Number of misclassifications (updates) in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src=\"../../assets/practice.png\"\n",
    "     alt=\"practice\"\n",
    "     style=\"width: 100px; float: right\" />\n",
    "\n",
    "## Part III: Complete the Adaline classifier\n",
    "\n",
    "**Try to implement as much as possible without consulting the solution.**\n",
    "\n",
    "**Resources:**\n",
    "* Solution: Ch02 - page 27, 3rd Edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T08:54:55.433568Z",
     "start_time": "2021-01-07T08:54:55.420310Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdalineGD(object):\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    cost_ : list\n",
    "      Sum-of-squares cost function value in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "        self.weights_ = [self.w_.copy()] # OT: collect inital weights in a list\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            # Please note that the \"activation\" method has no effect\n",
    "            # in the code since it is simply an identity function. We\n",
    "            # could write `output = self.net_input(X)` directly instead.\n",
    "            # The purpose of the activation is more conceptual, i.e.,  \n",
    "            # in the case of logistic regression (as we will see later), \n",
    "            # we could change it to\n",
    "            # a sigmoid function to implement a logistic regression classifier.\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "            self.weights_.append(self.w_.copy()) # OT: append copy of weight in list\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src=\"../../assets/practice.png\"\n",
    "     alt=\"practice\"\n",
    "     style=\"width: 100px; float: right\" />\n",
    "\n",
    "## Part IV: Compare results on the Breast Cancer dataset\n",
    "\n",
    "**Try to implement as much as possible without consulting the solution.**\n",
    "\n",
    "**Resources:**\n",
    "* Solution: Ch02 - page 27, 3rd Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to load the Breast Cancer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T08:54:55.960764Z",
     "start_time": "2021-01-07T08:54:55.438063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (569, 30)\n",
      "Shape of y: (569,)\n",
      "Distribution of targets: {'malignant': 212, 'benign': 357}\n",
      "Shape of X_train: (426, 30)\n",
      "Shape of X_test: (143, 30)\n",
      "Shape of y_train: (426,)\n",
      "Shape of y_test: (143,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import data\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "# Extract feature and target names\n",
    "feature_names = cancer_data.feature_names\n",
    "target_names = cancer_data.target_names\n",
    "\n",
    "# Define feature data\n",
    "X = cancer_data.data\n",
    "print(f'Shape of X: {X.shape}')\n",
    "\n",
    "# Define target data\n",
    "y = cancer_data.target\n",
    "\n",
    "# Convert y-valus to [-1 1]\n",
    "y = np.where(y==1, 1, -1)\n",
    "print(f'Shape of y: {y.shape}')\n",
    "\n",
    "# Print distribution of targets\n",
    "targets, counts = np.unique(y, return_counts=True)\n",
    "target_count = {target_names[i]: counts[i] for i in range(len(targets))}\n",
    "print(f'Distribution of targets: {target_count}')\n",
    "\n",
    "# Divide training data into train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=123)\n",
    "\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')\n",
    "\n",
    "# Scale traning and test data\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================\n",
    "\n",
    "### A) Perceptron prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a perceptron using the Perceptron class above and find the F1-score for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T08:54:56.227389Z",
     "start_time": "2021-01-07T08:54:55.963283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for Perceptron model:  0.96045197740113\n"
     ]
    }
   ],
   "source": [
    "# Create perceptron instance\n",
    "perceptron = Perceptron(eta=0.01, n_iter=50, random_state=123)\n",
    "\n",
    "# Fit perceptron to training data\n",
    "perceptron.fit(X_train_sc, y_train)\n",
    "\n",
    "# Make prediciton\n",
    "y_pred_perceptron = perceptron.predict(X_test_sc)\n",
    "\n",
    "# Print f1-score for prediction\n",
    "print('F1-score for Perceptron model: ', f1_score(y_test, y_pred_perceptron))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================\n",
    "\n",
    "### B) Adaline prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train an adaline instance using the Adaline class above and find the F1-score for the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T08:54:56.246962Z",
     "start_time": "2021-01-07T08:54:56.229315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for Adaline model:  0.9782608695652174\n"
     ]
    }
   ],
   "source": [
    "# Create perceptron instance\n",
    "adaline = AdalineGD(eta=0.0001, n_iter=50, random_state=123)\n",
    "\n",
    "# Fit perceptron to training data\n",
    "adaline.fit(X_train_sc, y_train)\n",
    "\n",
    "# Make prediciton\n",
    "y_pred_adaline = adaline.predict(X_test_sc)\n",
    "\n",
    "# Print f1-score for prediction\n",
    "print('F1-score for Adaline model: ', f1_score(y_test, y_pred_adaline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================\n",
    "\n",
    "### C) Tweak models and compare results\n",
    "\n",
    "Try changing learning rates and iterations for both models. Which model is more precise? Which is more sensitive to input parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================\n",
    "\n",
    "### Bonus question:\n",
    "\n",
    "Try running the Adaline model on the training data with the following parameters:\n",
    "* eta: 0.1\n",
    "* n_iter: 50\n",
    "* random_state: 123\n",
    "\n",
    "Comment on the result of the prediction. What do you think is the reason for the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
